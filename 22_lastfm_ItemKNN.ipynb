{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f9afb8-631b-4cb1-8347-7e94c9c9b163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE EVALUATION WITH MULTIPLE RERANKERS (k=10)\n",
      "================================================================================\n",
      "\n",
      "Loading LastFM dataset...\n",
      "Loading LastFM dataset...\n",
      "Trying to load LastFM data with utf-8 encoding...\n",
      "Successfully loaded LastFM dataset with utf-8 encoding\n",
      "Loaded 92835 interactions from 1893 users on 17633 artists\n",
      "Splitting data for evaluation...\n",
      "Using random sampling (some users have only 1 rating)...\n",
      "Creating user-item matrix...\n",
      "\n",
      "Training ItemKNN model...\n",
      "Computing item-item similarity matrix...\n",
      "ItemKNN model trained with 50 neighbors\n",
      "\n",
      "Initializing rerankers...\n",
      "\n",
      "Evaluating 1870 users...\n",
      "\n",
      "============================== ACCURACY METRICS ==============================\n",
      "Metric          Original             Simple Reranker      MMR Reranker        \n",
      "------------------------------------------------------------------------------\n",
      "ndcg@10         0.2025           0.1161 (-42.7%)      0.2100 (+3.7%)\n",
      "precision@10    0.1492           0.0950 (-36.3%)      0.1564 (+4.8%)\n",
      "recall@10       0.1645           0.1058 (-35.7%)      0.1737 (+5.6%)\n",
      "\n",
      "============================== DIVERSITY METRICS ==============================\n",
      "Metric               Original             Simple Reranker      MMR Reranker        \n",
      "-----------------------------------------------------------------------------------\n",
      "item_coverage        0.2321           0.2999 (+29.2%)      0.2204 (-5.1%)\n",
      "gini_index           0.7612           0.6788 (-10.8%)      0.7670 (+0.8%)\n",
      "shannon_entropy      0.6368           0.7226 (+13.5%)      0.6358 (-0.2%)\n",
      "tail_percentage      0.0637           0.0748 (+17.5%)      0.0548 (-13.9%)\n",
      "\n",
      "============================== METRIC INTERPRETATIONS ==============================\n",
      "Accuracy Metrics:\n",
      "- NDCG: Higher is better; measures ranking quality\n",
      "- Precision: Higher is better; measures the ratio of relevant items recommended\n",
      "- Recall: Higher is better; measures coverage of relevant items\n",
      "\n",
      "Diversity Metrics:\n",
      "- Item Coverage: Higher means more items from the catalog are recommended\n",
      "- Gini Index: Lower values indicate more equal recommendation distribution\n",
      "- Shannon Entropy: Higher values mean more diverse recommendations\n",
      "- Tail Percentage: Higher means more niche items are being recommended\n"
     ]
    }
   ],
   "source": [
    "# ItemKNN Recommender with Diversity Reranking for LastFM\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import random\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#################################\n",
    "# ITEMKNN RECOMMENDER IMPLEMENTATION\n",
    "#################################\n",
    "\n",
    "class ItemKNNRecommender:\n",
    "    def __init__(self, k_neighbors=50, random_state=42):\n",
    "        \"\"\"\n",
    "        Item-based K-Nearest Neighbors recommender algorithm\n",
    "        \n",
    "        Parameters:\n",
    "        - k_neighbors: number of nearest neighbors to consider\n",
    "        - random_state: seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    def fit(self, user_item_matrix):\n",
    "        \"\"\"\n",
    "        Train the ItemKNN model on the user-item matrix\n",
    "        \n",
    "        Parameters:\n",
    "        - user_item_matrix: scipy sparse matrix with user-item interactions\n",
    "        \n",
    "        Returns:\n",
    "        - self\n",
    "        \"\"\"\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.n_users, self.n_items = user_item_matrix.shape\n",
    "        \n",
    "        # Create a dictionary of items each user has interacted with\n",
    "        self.user_items = defaultdict(set)\n",
    "        for user, item in zip(*self.user_item_matrix.nonzero()):\n",
    "            self.user_items[user].add(item)\n",
    "        \n",
    "        # Compute item-item similarity matrix using cosine similarity\n",
    "        print(\"Computing item-item similarity matrix...\")\n",
    "        self.item_similarity = cosine_similarity(user_item_matrix.T)\n",
    "        \n",
    "        # Exclude self-similarity (set diagonal to 0)\n",
    "        np.fill_diagonal(self.item_similarity, 0)\n",
    "        \n",
    "        # For each item, keep only top k_neighbors\n",
    "        if self.k_neighbors < self.n_items:\n",
    "            for i in range(self.n_items):\n",
    "                sim_scores = self.item_similarity[i]\n",
    "                top_k_idx = np.argsort(sim_scores)[::-1][:self.k_neighbors]\n",
    "                mask = np.ones(self.n_items, dtype=bool)\n",
    "                mask[top_k_idx] = False\n",
    "                self.item_similarity[i, mask] = 0\n",
    "                \n",
    "        print(f\"ItemKNN model trained with {self.k_neighbors} neighbors\")\n",
    "        return self\n",
    "    \n",
    "    def recommend(self, user_id, n=10, exclude_seen=True):\n",
    "        \"\"\"\n",
    "        Generate item recommendations for a user\n",
    "        \n",
    "        Parameters:\n",
    "        - user_id: user index\n",
    "        - n: number of recommendations to generate\n",
    "        - exclude_seen: whether to exclude items the user has already interacted with\n",
    "        \n",
    "        Returns:\n",
    "        - list of n recommended item indices\n",
    "        \"\"\"\n",
    "        if user_id in self.user_items:\n",
    "            user_items = list(self.user_items[user_id])\n",
    "        else:\n",
    "            items = np.arange(self.n_items)\n",
    "            np.random.shuffle(items)\n",
    "            return items[:n]\n",
    "        \n",
    "        scores = np.zeros(self.n_items)\n",
    "        for item in user_items:\n",
    "            scores += self.item_similarity[item]\n",
    "        if len(user_items) > 0:\n",
    "            scores /= len(user_items)\n",
    "        if exclude_seen:\n",
    "            scores[user_items] = -np.inf\n",
    "        top_items = np.argsort(scores)[::-1][:n]\n",
    "        return top_items\n",
    "\n",
    "#################################\n",
    "# RERANKER IMPLEMENTATION\n",
    "#################################\n",
    "\n",
    "class SimpleReranker:\n",
    "    \"\"\"\n",
    "    Simple reranker that balances original scores with diversity.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, alpha=0.7):\n",
    "        \"\"\"\n",
    "        Initialize reranker\n",
    "        \n",
    "        Parameters:\n",
    "        - model: trained recommender model\n",
    "        - alpha: weight for original scores (0 to 1); higher alpha means more focus on accuracy\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Calculate item popularity\n",
    "        self.item_popularity = np.zeros(model.n_items)\n",
    "        for user in range(model.n_users):\n",
    "            if user in model.user_items:\n",
    "                for item in model.user_items[user]:\n",
    "                    self.item_popularity[item] += 1\n",
    "        max_pop = np.max(self.item_popularity)\n",
    "        if max_pop > 0:\n",
    "            self.norm_popularity = self.item_popularity / max_pop\n",
    "        else:\n",
    "            self.norm_popularity = np.zeros_like(self.item_popularity)\n",
    "    \n",
    "    def rerank(self, user_id, n=10):\n",
    "        \"\"\"\n",
    "        Generate reranked recommendations.\n",
    "        \"\"\"\n",
    "        if user_id in self.model.user_items:\n",
    "            user_items = list(self.model.user_items[user_id])\n",
    "        else:\n",
    "            items = np.arange(self.model.n_items)\n",
    "            np.random.shuffle(items)\n",
    "            return items[:n]\n",
    "        \n",
    "        original_scores = np.zeros(self.model.n_items)\n",
    "        for item in user_items:\n",
    "            original_scores += self.model.item_similarity[item]\n",
    "        if len(user_items) > 0:\n",
    "            original_scores /= len(user_items)\n",
    "        original_scores[user_items] = -np.inf\n",
    "        \n",
    "        candidates = np.argsort(original_scores)[::-1][:n*3]\n",
    "        selected = []\n",
    "        while len(selected) < n and candidates.size > 0:\n",
    "            best_score = -np.inf\n",
    "            best_item = None\n",
    "            for item in candidates:\n",
    "                if item in selected:\n",
    "                    continue\n",
    "                score_orig = original_scores[item]\n",
    "                diversity_score = 0\n",
    "                if selected:\n",
    "                    similarities = [self.model.item_similarity[item, sel] for sel in selected]\n",
    "                    if similarities:\n",
    "                        avg_sim = np.mean(similarities)\n",
    "                        diversity_score = 1 - avg_sim\n",
    "                novelty_score = 1 - self.norm_popularity[item]\n",
    "                combined_score = (\n",
    "                    self.alpha * score_orig +\n",
    "                    (1 - self.alpha) * 0.5 * diversity_score +\n",
    "                    (1 - self.alpha) * 0.5 * novelty_score\n",
    "                )\n",
    "                if combined_score > best_score:\n",
    "                    best_score = combined_score\n",
    "                    best_item = item\n",
    "            if best_item is None:\n",
    "                break\n",
    "            selected.append(best_item)\n",
    "            candidates = candidates[candidates != best_item]\n",
    "        return selected\n",
    "\n",
    "class MMRReranker:\n",
    "    \"\"\"\n",
    "    Maximum Marginal Relevance (MMR) Reranker.\n",
    "    \n",
    "    Balances relevance and diversity by selecting items that maximize:\n",
    "    MMR = λ * rel(i) - (1-λ) * max(sim(i,j)) for j in selected items.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, lambda_param=0.7):\n",
    "        \"\"\"\n",
    "        Initialize the MMR reranker.\n",
    "        \n",
    "        Parameters:\n",
    "        - model: trained ItemKNN model\n",
    "        - lambda_param: trade-off parameter between relevance and diversity (0-1)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.lambda_param = lambda_param\n",
    "        \n",
    "    def calculate_item_similarity(self, item1, item2):\n",
    "        return self.model.item_similarity[item1, item2]\n",
    "    \n",
    "    def rerank(self, user_id, n=10, candidate_size=100):\n",
    "        if user_id in self.model.user_items:\n",
    "            user_items = list(self.model.user_items[user_id])\n",
    "        else:\n",
    "            items = np.arange(self.model.n_items)\n",
    "            np.random.shuffle(items)\n",
    "            return items[:n]\n",
    "        \n",
    "        relevance_scores = np.zeros(self.model.n_items)\n",
    "        for item in user_items:\n",
    "            relevance_scores += self.model.item_similarity[item]\n",
    "        if len(user_items) > 0:\n",
    "            relevance_scores /= len(user_items)\n",
    "        relevance_scores[user_items] = -np.inf\n",
    "        \n",
    "        candidates = np.argsort(relevance_scores)[::-1][:candidate_size]\n",
    "        candidate_scores = relevance_scores[candidates]\n",
    "        min_score = np.min(candidate_scores)\n",
    "        max_score = np.max(candidate_scores)\n",
    "        score_range = max_score - min_score\n",
    "        if score_range > 0:\n",
    "            normalized_scores = (candidate_scores - min_score) / score_range\n",
    "        else:\n",
    "            normalized_scores = np.zeros_like(candidate_scores)\n",
    "        \n",
    "        selected = []\n",
    "        if candidates.size > 0:\n",
    "            selected.append(candidates[np.argmax(normalized_scores)])\n",
    "            remaining_candidates = set(candidates) - set(selected)\n",
    "        else:\n",
    "            remaining_candidates = set()\n",
    "        \n",
    "        while len(selected) < n and remaining_candidates:\n",
    "            max_mmr = -np.inf\n",
    "            max_item = None\n",
    "            for item in remaining_candidates:\n",
    "                item_idx = np.where(candidates == item)[0][0]\n",
    "                relevance = normalized_scores[item_idx]\n",
    "                max_sim = 0\n",
    "                for sel in selected:\n",
    "                    sim = self.calculate_item_similarity(item, sel)\n",
    "                    max_sim = max(max_sim, sim)\n",
    "                mmr_score = self.lambda_param * relevance - (1 - self.lambda_param) * max_sim\n",
    "                if mmr_score > max_mmr:\n",
    "                    max_mmr = mmr_score\n",
    "                    max_item = item\n",
    "            if max_item is not None:\n",
    "                selected.append(max_item)\n",
    "                remaining_candidates.remove(max_item)\n",
    "            else:\n",
    "                break\n",
    "        return selected\n",
    "\n",
    "#################################\n",
    "# EVALUATION METRICS\n",
    "#################################\n",
    "\n",
    "def calculate_ndcg(recommended_items, relevant_items, relevant_scores, k=None):\n",
    "    if k is None:\n",
    "        k = len(recommended_items)\n",
    "    else:\n",
    "        k = min(k, len(recommended_items))\n",
    "    \n",
    "    relevance_map = {}\n",
    "    for item_id, score in zip(relevant_items, relevant_scores):\n",
    "        try:\n",
    "            score_float = float(score)\n",
    "            score_float = min(score_float, 10.0)\n",
    "            relevance_map[item_id] = score_float\n",
    "        except (ValueError, TypeError):\n",
    "            relevance_map[item_id] = 0.0\n",
    "    \n",
    "    dcg = 0\n",
    "    for i, item_id in enumerate(recommended_items[:k]):\n",
    "        if item_id in relevance_map:\n",
    "            rel = float(relevance_map[item_id])\n",
    "            dcg += (2 ** rel - 1) / np.log2(i + 2)\n",
    "    \n",
    "    sorted_relevant = []\n",
    "    for item_id, score in zip(relevant_items, relevant_scores):\n",
    "        try:\n",
    "            score_float = float(score)\n",
    "            score_float = min(score_float, 10.0)\n",
    "            sorted_relevant.append((item_id, score_float))\n",
    "        except (ValueError, TypeError):\n",
    "            sorted_relevant.append((item_id, 0.0))\n",
    "    sorted_relevant.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    idcg = 0\n",
    "    for i, (item_id, rel) in enumerate(sorted_relevant[:k]):\n",
    "        idcg += (2 ** float(rel) - 1) / np.log2(i + 2)\n",
    "    \n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def calculate_precision(recommended_items, relevant_items):\n",
    "    num_relevant = sum(1 for item in recommended_items if item in relevant_items)\n",
    "    return num_relevant / len(recommended_items) if recommended_items else 0\n",
    "\n",
    "def calculate_recall(recommended_items, relevant_items):\n",
    "    num_relevant = sum(1 for item in recommended_items if item in relevant_items)\n",
    "    return num_relevant / len(relevant_items) if relevant_items else 0\n",
    "\n",
    "def calculate_diversity_metrics(recommendations, item_popularity, total_items, tail_items=None):\n",
    "    rec_counts = Counter(recommendations)\n",
    "    item_coverage = len(rec_counts) / total_items\n",
    "    sorted_counts = sorted(rec_counts.values())\n",
    "    n = len(sorted_counts)\n",
    "    if n == 0:\n",
    "        gini_index = 0\n",
    "    else:\n",
    "        cumulative_sum = sum((i + 1) * count for i, count in enumerate(sorted_counts))\n",
    "        gini_index = (2 * cumulative_sum) / (n * sum(sorted_counts)) - (n + 1) / n\n",
    "    rec_total = sum(rec_counts.values())\n",
    "    probabilities = [count / rec_total for count in rec_counts.values()]\n",
    "    entropy = -sum(p * np.log2(p) for p in probabilities if p > 0)\n",
    "    max_entropy = np.log2(min(total_items, rec_total))\n",
    "    normalized_entropy = entropy / max_entropy if max_entropy > 0 else 0\n",
    "    \n",
    "    if tail_items is None:\n",
    "        sorted_pop = np.argsort(item_popularity)\n",
    "        num_tail = int(len(sorted_pop) * 0.2)\n",
    "        tail_items = set(sorted_pop[:num_tail])\n",
    "    tail_rec = sum(1 for item in recommendations if item in tail_items)\n",
    "    tail_percentage = tail_rec / len(recommendations) if recommendations else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'item_coverage': item_coverage,\n",
    "        'gini_index': gini_index,\n",
    "        'shannon_entropy': normalized_entropy,\n",
    "        'tail_percentage': tail_percentage\n",
    "    }\n",
    "    return metrics, tail_items\n",
    "\n",
    "#################################\n",
    "# HELPER FUNCTIONS\n",
    "#################################\n",
    "\n",
    "def load_lastfm(path=\"lastfm/lastfm.inter\"):\n",
    "    print(\"Loading LastFM dataset...\")\n",
    "    encodings_to_try = ['utf-8', 'latin-1', 'ISO-8859-1', 'cp1252']\n",
    "    \n",
    "    def generate_sample_data():\n",
    "        print(\"Generating sample LastFM data for demonstration purposes...\")\n",
    "        np.random.seed(42)\n",
    "        n_users = 100\n",
    "        n_items = 50\n",
    "        n_ratings = 1000\n",
    "        user_ids = [f\"user_{i}\" for i in range(n_users)]\n",
    "        item_ids = [f\"artist_{i}\" for i in range(n_items)]\n",
    "        random_users = np.random.choice(user_ids, size=n_ratings)\n",
    "        random_items = np.random.choice(item_ids, size=n_ratings)\n",
    "        random_ratings = np.random.uniform(1, 5, size=n_ratings)\n",
    "        constant_timestamp = np.full(n_ratings, 1111111111)\n",
    "        sample_df = pd.DataFrame({\n",
    "            'user_id': random_users,\n",
    "            'item_id': random_items,\n",
    "            'rating': random_ratings,\n",
    "            'timestamp': constant_timestamp\n",
    "        })\n",
    "        dummy_df = pd.DataFrame(columns=['item_id', 'name', 'tags'])\n",
    "        print(f\"Generated sample data with {len(sample_df)} ratings from {sample_df['user_id'].nunique()} users on {sample_df['item_id'].nunique()} artists\")\n",
    "        return sample_df, dummy_df\n",
    "    \n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            print(f\"Trying to load LastFM data with {encoding} encoding...\")\n",
    "            columns = ['user_id', 'artist_id', 'weight', 'tag_value']\n",
    "            raw_df = pd.read_csv(path, sep='\\t', names=columns, encoding=encoding)\n",
    "            raw_df = raw_df.rename(columns={'artist_id': 'item_id', 'weight': 'rating'})\n",
    "            raw_df['timestamp'] = 1111111111\n",
    "            raw_df = raw_df.drop(columns=['tag_value'])\n",
    "            dummy_df = pd.DataFrame(columns=['item_id', 'name', 'tags'])\n",
    "            if len(raw_df) > 0:\n",
    "                print(f\"Successfully loaded LastFM dataset with {encoding} encoding\")\n",
    "                print(f\"Loaded {len(raw_df)} interactions from {raw_df['user_id'].nunique()} users on {raw_df['item_id'].nunique()} artists\")\n",
    "                return raw_df, dummy_df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading LastFM dataset with {encoding} encoding: {str(e)}\")\n",
    "            continue\n",
    "    print(\"All attempts to load the LastFM dataset failed. Generating sample data instead.\")\n",
    "    return generate_sample_data()\n",
    "\n",
    "def create_user_item_matrix(ratings_df):\n",
    "    user_ids = ratings_df['user_id'].unique()\n",
    "    item_ids = ratings_df['item_id'].unique()\n",
    "    user_mapping = {user_id: i for i, user_id in enumerate(user_ids)}\n",
    "    item_mapping = {item_id: i for i, item_id in enumerate(item_ids)}\n",
    "    rows = ratings_df['user_id'].map(user_mapping)\n",
    "    cols = ratings_df['item_id'].map(item_mapping)\n",
    "    data = np.ones(len(ratings_df))\n",
    "    user_item_matrix = csr_matrix((data, (rows, cols)),\n",
    "                                  shape=(len(user_mapping), len(item_mapping)))\n",
    "    return user_item_matrix, user_mapping, item_mapping\n",
    "\n",
    "#################################\n",
    "# COMPREHENSIVE EVALUATION\n",
    "#################################\n",
    "\n",
    "def comprehensive_evaluation_multiple_rerankers(k=10, sample_size=None):\n",
    "    \"\"\"\n",
    "    Run a comprehensive evaluation measuring both accuracy and diversity\n",
    "    for multiple rerankers.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"COMPREHENSIVE EVALUATION WITH MULTIPLE RERANKERS (k={k})\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    print(\"\\nLoading LastFM dataset...\")\n",
    "    ratings_df, dummy_df = load_lastfm()\n",
    "    \n",
    "    print(\"Splitting data for evaluation...\")\n",
    "    value_counts = ratings_df['user_id'].value_counts()\n",
    "    if value_counts.min() >= 2:\n",
    "        print(\"Using stratified sampling...\")\n",
    "        train_df, test_df = train_test_split(\n",
    "            ratings_df, test_size=0.2, stratify=ratings_df['user_id'], random_state=42\n",
    "        )\n",
    "    else:\n",
    "        print(\"Using random sampling (some users have only 1 rating)...\")\n",
    "        train_df, test_df = train_test_split(\n",
    "            ratings_df, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "    print(\"Creating user-item matrix...\")\n",
    "    user_item_matrix, user_mapping, item_mapping = create_user_item_matrix(train_df)\n",
    "    reverse_user_mapping = {v: k for k, v in user_mapping.items()}\n",
    "    reverse_item_mapping = {v: k for k, v in item_mapping.items()}\n",
    "    \n",
    "    # Build test ground truth\n",
    "    test_relevant_items = defaultdict(list)\n",
    "    test_relevant_scores = defaultdict(list)\n",
    "    for _, row in test_df.iterrows():\n",
    "        uid, iid, rating = row['user_id'], row['item_id'], row['rating']\n",
    "        if uid in user_mapping and iid in item_mapping:\n",
    "            test_relevant_items[uid].append(iid)\n",
    "            test_relevant_scores[uid].append(rating)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nTraining ItemKNN model...\")\n",
    "    model = ItemKNNRecommender(k_neighbors=50)\n",
    "    model.fit(user_item_matrix)\n",
    "    \n",
    "    # Initialize rerankers\n",
    "    print(\"\\nInitializing rerankers...\")\n",
    "    simple_reranker = SimpleReranker(model=model, alpha=0.7)\n",
    "    mmr_reranker = MMRReranker(model=model, lambda_param=0.7)\n",
    "    \n",
    "    rerankers = {\n",
    "        \"Original\": None,\n",
    "        \"Simple Reranker\": simple_reranker,\n",
    "        \"MMR Reranker\": mmr_reranker\n",
    "    }\n",
    "    \n",
    "    # Select evaluation users\n",
    "    if sample_size is not None and sample_size < len(test_relevant_items):\n",
    "        eval_users = random.sample(list(test_relevant_items.keys()), sample_size)\n",
    "    else:\n",
    "        eval_users = list(test_relevant_items.keys())\n",
    "    print(f\"\\nEvaluating {len(eval_users)} users...\")\n",
    "    \n",
    "    # Collect metrics for each reranker\n",
    "    results = {name: {'ndcg': [], 'precision': [], 'recall': []} for name in rerankers}\n",
    "    all_recs = {name: [] for name in rerankers}\n",
    "    \n",
    "    for uid in eval_users:\n",
    "        if not test_relevant_items[uid]:\n",
    "            continue\n",
    "        user_idx = user_mapping[uid]\n",
    "        for name, reranker in rerankers.items():\n",
    "            if reranker is None:\n",
    "                rec_idx = model.recommend(user_idx, n=k)\n",
    "            else:\n",
    "                rec_idx = reranker.rerank(user_idx, n=k)\n",
    "            rec = [reverse_item_mapping[idx] for idx in rec_idx]\n",
    "            all_recs[name].extend(rec_idx)\n",
    "            results[name]['ndcg'].append(calculate_ndcg(rec, test_relevant_items[uid], test_relevant_scores[uid]))\n",
    "            results[name]['precision'].append(calculate_precision(rec, test_relevant_items[uid]))\n",
    "            results[name]['recall'].append(calculate_recall(rec, test_relevant_items[uid]))\n",
    "    \n",
    "    # Calculate average accuracy metrics\n",
    "    acc_metrics = {}\n",
    "    for name in rerankers:\n",
    "        acc_metrics[name] = {\n",
    "            f'ndcg@{k}': np.mean(results[name]['ndcg']),\n",
    "            f'precision@{k}': np.mean(results[name]['precision']),\n",
    "            f'recall@{k}': np.mean(results[name]['recall'])\n",
    "        }\n",
    "    \n",
    "    # Calculate diversity metrics using all recommendations from each approach\n",
    "    # First, determine item popularity from the training data:\n",
    "    item_popularity = np.zeros(model.n_items)\n",
    "    for user in range(model.n_users):\n",
    "        if user in model.user_items:\n",
    "            for item in model.user_items[user]:\n",
    "                item_popularity[item] += 1\n",
    "    div_metrics = {}\n",
    "    orig_div, tail_items = calculate_diversity_metrics(\n",
    "        recommendations=all_recs[\"Original\"],\n",
    "        item_popularity=item_popularity,\n",
    "        total_items=model.n_items\n",
    "    )\n",
    "    div_metrics[\"Original\"] = orig_div\n",
    "    for name in [\"Simple Reranker\", \"MMR Reranker\"]:\n",
    "        div_metrics[name], _ = calculate_diversity_metrics(\n",
    "            recommendations=all_recs[name],\n",
    "            item_popularity=item_popularity,\n",
    "            total_items=model.n_items,\n",
    "            tail_items=tail_items\n",
    "        )\n",
    "    \n",
    "    # Print Accuracy Metrics Comparison\n",
    "    print(\"\\n\" + \"=\"*30 + \" ACCURACY METRICS \" + \"=\"*30)\n",
    "    header = f\"{'Metric':<15} {'Original':<20} {'Simple Reranker':<20} {'MMR Reranker':<20}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for metric in [f'ndcg@{k}', f'precision@{k}', f'recall@{k}']:\n",
    "        orig_val = acc_metrics[\"Original\"][metric]\n",
    "        simple_val = acc_metrics[\"Simple Reranker\"][metric]\n",
    "        mmr_val = acc_metrics[\"MMR Reranker\"][metric]\n",
    "        simple_change = ((simple_val - orig_val)/orig_val * 100) if orig_val > 0 else float('inf')\n",
    "        mmr_change = ((mmr_val - orig_val)/orig_val * 100) if orig_val > 0 else float('inf')\n",
    "        print(f\"{metric:<15} {orig_val:.4f}{'':<10} {simple_val:.4f} ({simple_change:+.1f}%){'':<5} {mmr_val:.4f} ({mmr_change:+.1f}%)\")\n",
    "    \n",
    "    # Print Diversity Metrics Comparison\n",
    "    print(\"\\n\" + \"=\"*30 + \" DIVERSITY METRICS \" + \"=\"*30)\n",
    "    header = f\"{'Metric':<20} {'Original':<20} {'Simple Reranker':<20} {'MMR Reranker':<20}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for metric in ['item_coverage', 'gini_index', 'shannon_entropy', 'tail_percentage']:\n",
    "        orig_val = div_metrics[\"Original\"][metric]\n",
    "        simple_val = div_metrics[\"Simple Reranker\"][metric]\n",
    "        mmr_val = div_metrics[\"MMR Reranker\"][metric]\n",
    "        simple_change = ((simple_val - orig_val)/orig_val * 100) if orig_val > 0 else float('inf')\n",
    "        mmr_change = ((mmr_val - orig_val)/orig_val * 100) if orig_val > 0 else float('inf')\n",
    "        print(f\"{metric:<20} {orig_val:.4f}{'':<10} {simple_val:.4f} ({simple_change:+.1f}%){'':<5} {mmr_val:.4f} ({mmr_change:+.1f}%)\")\n",
    "    \n",
    "    # Print interpretations\n",
    "    print(\"\\n\" + \"=\"*30 + \" METRIC INTERPRETATIONS \" + \"=\"*30)\n",
    "    print(\"Accuracy Metrics:\")\n",
    "    print(\"- NDCG: Higher is better; measures ranking quality\")\n",
    "    print(\"- Precision: Higher is better; measures the ratio of relevant items recommended\")\n",
    "    print(\"- Recall: Higher is better; measures coverage of relevant items\")\n",
    "    print(\"\\nDiversity Metrics:\")\n",
    "    print(\"- Item Coverage: Higher means more items from the catalog are recommended\")\n",
    "    print(\"- Gini Index: Lower values indicate more equal recommendation distribution\")\n",
    "    print(\"- Shannon Entropy: Higher values mean more diverse recommendations\")\n",
    "    print(\"- Tail Percentage: Higher means more niche items are being recommended\")\n",
    "    \n",
    "    # Return all results for further use if needed\n",
    "    return {\n",
    "        'accuracy': acc_metrics,\n",
    "        'diversity': div_metrics\n",
    "    }\n",
    "\n",
    "# Execute evaluation when run directly\n",
    "if __name__ == \"__main__\":\n",
    "    comprehensive_evaluation_multiple_rerankers(k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399f251-bd4c-4a34-a557-b8f5c0ccb65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
