{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee03257b-dbbb-42be-bd7e-ff9843e2eac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE EVALUATION WITH MULTIPLE RERANKERS (k=10)\n",
      "================================================================================\n",
      "\n",
      "Loading Epinions dataset...\n",
      "Trying to load Epinions data with utf-8 encoding...\n",
      "Error loading Epinions dataset with utf-8 encoding: 'utf-8' codec can't decode byte 0xa3 in position 4953: invalid start byte\n",
      "Trying to load Epinions data with latin-1 encoding...\n",
      "Successfully loaded Epinions dataset with latin-1 encoding\n",
      "Loaded 189083 ratings from 115842 users on 41764 items\n",
      "Splitting data for evaluation...\n",
      "Using random sampling (some users have only 1 rating)...\n",
      "Creating user-item matrix...\n",
      "\n",
      "Training NeuMF model...\n",
      "Training NeuMF model for 10 epochs...\n",
      "Epoch 1/10, Loss: 0.4454, Time: 10.86s\n",
      "Epoch 5/10, Loss: 0.0613, Time: 13.64s\n",
      "Epoch 10/10, Loss: 0.0036, Time: 10.38s\n",
      "\n",
      "Initializing rerankers...\n",
      "\n",
      "Evaluating 11335 users...\n",
      "\n",
      "Evaluating Original NeuMF...\n",
      "\n",
      "Evaluating Simple Reranker...\n",
      "\n",
      "Evaluating MMR Reranker...\n",
      "\n",
      "============================== ACCURACY METRICS COMPARISON ==============================\n",
      "Metric         Original NeuMF      Simple Reranker     MMR Reranker        \n",
      "--------------------------------------------------------------------------------\n",
      "ndcg@10        0.0013               0.0010 (-28.0%)     0.0012 (-8.4%)     \n",
      "precision@10   0.0004               0.0003 (-14.3%)     0.0004 (+7.1%)     \n",
      "recall@10      0.0025               0.0022 (-15.3%)     0.0026 (+1.2%)     \n",
      "\n",
      "============================== DIVERSITY METRICS COMPARISON ==============================\n",
      "Metric         Original NeuMF      Simple Reranker     MMR Reranker        \n",
      "--------------------------------------------------------------------------------\n",
      "item_coverage  0.4244               0.4314 (+1.7%)     0.4111 (-3.1%)     \n",
      "gini_index     0.6539               0.6249 (-4.4%)     0.6460 (-1.2%)     \n",
      "shannon_entropy0.8324               0.8480 (+1.9%)     0.8346 (+0.3%)     \n",
      "tail_percentage0.0074               0.0074 (-0.2%)     0.0061 (-18.4%)     \n",
      "\n",
      "============================== METRIC INTERPRETATIONS ==============================\n",
      "Accuracy Metrics:\n",
      "- NDCG: Higher is better, measures ranking quality\n",
      "- Precision: Higher is better, measures relevant item ratio in recommendations\n",
      "- Recall: Higher is better, measures coverage of all relevant items\n",
      "\n",
      "Diversity Metrics:\n",
      "- Item Coverage: Higher means more catalog items are recommended\n",
      "- Gini Index: Lower means more equality in item recommendations\n",
      "- Shannon Entropy: Higher means more diverse recommendations\n",
      "- Tail Percentage: Higher means more niche items are recommended\n"
     ]
    }
   ],
   "source": [
    "# NeuMF Recommender with Diversity Reranking\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#################################\n",
    "# NEUMF RECOMMENDER IMPLEMENTATION\n",
    "#################################\n",
    "\n",
    "class NCFDataset(Dataset):\n",
    "    \"\"\"Dataset for NCF\"\"\"\n",
    "    def __init__(self, user_item_matrix, neg_samples=4):\n",
    "        \"\"\"\n",
    "        Initialize the dataset\n",
    "        \n",
    "        Parameters:\n",
    "        - user_item_matrix: scipy sparse matrix with user-item interactions\n",
    "        - neg_samples: number of negative samples per positive interaction\n",
    "        \"\"\"\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.users, self.items = user_item_matrix.nonzero()\n",
    "        self.n_users = user_item_matrix.shape[0]\n",
    "        self.n_items = user_item_matrix.shape[1]\n",
    "        self.neg_samples = neg_samples\n",
    "        \n",
    "        # Create a set of (user, item) pairs for quick lookup\n",
    "        self.user_item_set = set(zip(self.users, self.items))\n",
    "        \n",
    "        # Create a dictionary of items each user has interacted with\n",
    "        self.user_items = defaultdict(set)\n",
    "        for u, i in zip(self.users, self.items):\n",
    "            self.user_items[u].add(i)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.users) * (1 + self.neg_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Determine if this is a positive or negative sample\n",
    "        if idx < len(self.users):\n",
    "            # Positive sample\n",
    "            user = self.users[idx]\n",
    "            item = self.items[idx]\n",
    "            label = 1.0\n",
    "        else:\n",
    "            # Negative sample - sample a user and item that don't have an interaction\n",
    "            pos_idx = idx % len(self.users)\n",
    "            user = self.users[pos_idx]\n",
    "            \n",
    "            # Sample a negative item for this user\n",
    "            item = random.randint(0, self.n_items - 1)\n",
    "            while item in self.user_items[user]:\n",
    "                item = random.randint(0, self.n_items - 1)\n",
    "            \n",
    "            label = 0.0\n",
    "            \n",
    "        return user, item, label\n",
    "\n",
    "class GMF(nn.Module):\n",
    "    \"\"\"Generalized Matrix Factorization model\"\"\"\n",
    "    def __init__(self, n_users, n_items, latent_dim):\n",
    "        super(GMF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, latent_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, latent_dim)\n",
    "        self.output_layer = nn.Linear(latent_dim, 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        element_product = torch.mul(user_embeddings, item_embeddings)\n",
    "        output = self.output_layer(element_product)\n",
    "        return output.view(-1)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Multi-Layer Perceptron model\"\"\"\n",
    "    def __init__(self, n_users, n_items, latent_dim, layers=[64, 32, 16, 8]):\n",
    "        super(MLP, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, latent_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, latent_dim)\n",
    "        \n",
    "        # MLP layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        layer_dims = [2 * latent_dim] + layers\n",
    "        \n",
    "        for i in range(len(layer_dims) - 1):\n",
    "            self.layers.append(nn.Linear(layer_dims[i], layer_dims[i+1]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(layer_dims[-1], 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        vector = torch.cat([user_embeddings, item_embeddings], dim=-1)\n",
    "        \n",
    "        # Apply each layer\n",
    "        for layer in self.layers:\n",
    "            vector = layer(vector)\n",
    "            \n",
    "        output = self.output_layer(vector)\n",
    "        return output.view(-1)\n",
    "\n",
    "class NeuMF(nn.Module):\n",
    "    \"\"\"Neural Matrix Factorization model\"\"\"\n",
    "    def __init__(self, n_users, n_items, latent_dim=32, mlp_layers=[64, 32, 16, 8]):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.gmf = GMF(n_users, n_items, latent_dim)\n",
    "        self.mlp = MLP(n_users, n_items, latent_dim, mlp_layers)\n",
    "        \n",
    "        # NeuMF output layer\n",
    "        self.output_layer = nn.Linear(mlp_layers[-1] + latent_dim, 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.normal_(self.output_layer.weight, std=0.01)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        # GMF path\n",
    "        gmf_user = self.gmf.user_embedding(user_indices)\n",
    "        gmf_item = self.gmf.item_embedding(item_indices)\n",
    "        gmf_vector = torch.mul(gmf_user, gmf_item)\n",
    "        \n",
    "        # MLP path\n",
    "        mlp_user = self.mlp.user_embedding(user_indices)\n",
    "        mlp_item = self.mlp.item_embedding(item_indices)\n",
    "        mlp_vector = torch.cat([mlp_user, mlp_item], dim=-1)\n",
    "        \n",
    "        for layer in self.mlp.layers:\n",
    "            mlp_vector = layer(mlp_vector)\n",
    "        \n",
    "        # Concatenate GMF and MLP vectors\n",
    "        vector = torch.cat([gmf_vector, mlp_vector], dim=-1)\n",
    "        \n",
    "        # Final output\n",
    "        output = self.output_layer(vector)\n",
    "        \n",
    "        return torch.sigmoid(output.view(-1))\n",
    "\n",
    "class NeuMFRecommender:\n",
    "    def __init__(self, latent_dim=32, mlp_layers=[64, 32, 16, 8], epochs=20, batch_size=256, \n",
    "                 lr=0.001, neg_samples=4, device=None, random_state=42):\n",
    "        \"\"\"\n",
    "        Neural Matrix Factorization recommender algorithm\n",
    "        \n",
    "        Parameters:\n",
    "        - latent_dim: dimensionality of latent factors\n",
    "        - mlp_layers: list of layer sizes for MLP component\n",
    "        - epochs: number of training epochs\n",
    "        - batch_size: batch size for training\n",
    "        - lr: learning rate\n",
    "        - neg_samples: number of negative samples per positive interaction\n",
    "        - device: torch device (cpu or cuda)\n",
    "        - random_state: seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.latent_dim = latent_dim\n",
    "        self.mlp_layers = mlp_layers\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.neg_samples = neg_samples\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Set random seeds\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "        torch.manual_seed(random_state)\n",
    "        \n",
    "        # Set device\n",
    "        if device is None:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "    def fit(self, user_item_matrix):\n",
    "        \"\"\"\n",
    "        Train the NeuMF model on the user-item matrix\n",
    "        \n",
    "        Parameters:\n",
    "        - user_item_matrix: scipy sparse matrix with user-item interactions\n",
    "        \n",
    "        Returns:\n",
    "        - self\n",
    "        \"\"\"\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.n_users, self.n_items = user_item_matrix.shape\n",
    "        \n",
    "        # Create a dictionary of items each user has interacted with\n",
    "        self.user_items = defaultdict(set)\n",
    "        for user, item in zip(*self.user_item_matrix.nonzero()):\n",
    "            self.user_items[user].add(item)\n",
    "        \n",
    "        # Create dataset and dataloader\n",
    "        dataset = NCFDataset(user_item_matrix, neg_samples=self.neg_samples)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = NeuMF(self.n_users, self.n_items, self.latent_dim, self.mlp_layers).to(self.device)\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        # Training loop\n",
    "        print(f\"Training NeuMF model for {self.epochs} epochs...\")\n",
    "        self.model.train()\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            start_time = time.time()\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for users, items, labels in dataloader:\n",
    "                users = users.to(self.device)\n",
    "                items = items.to(self.device)\n",
    "                labels = labels.float().to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(users, items)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "                print(f\"Epoch {epoch+1}/{self.epochs}, Loss: {running_loss/len(dataloader):.4f}, Time: {elapsed_time:.2f}s\")\n",
    "        \n",
    "        # Switch to evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Precompute all user embeddings\n",
    "        with torch.no_grad():\n",
    "            self.user_gmf_embeddings = self.model.gmf.user_embedding.weight.data\n",
    "            self.item_gmf_embeddings = self.model.gmf.item_embedding.weight.data\n",
    "            self.user_mlp_embeddings = self.model.mlp.user_embedding.weight.data\n",
    "            self.item_mlp_embeddings = self.model.mlp.item_embedding.weight.data\n",
    "        \n",
    "        # Set up item factors (for compatibility with rerankers)\n",
    "        # We'll use a combination of GMF and MLP embeddings as item factors\n",
    "        self.item_factors = np.concatenate([\n",
    "            self.item_gmf_embeddings.cpu().numpy(),\n",
    "            self.item_mlp_embeddings.cpu().numpy()\n",
    "        ], axis=1)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def recommend(self, user_id, n=10, exclude_seen=True):\n",
    "        \"\"\"\n",
    "        Generate item recommendations for a user\n",
    "        \n",
    "        Parameters:\n",
    "        - user_id: user index\n",
    "        - n: number of recommendations to generate\n",
    "        - exclude_seen: whether to exclude items the user has already interacted with\n",
    "        \n",
    "        Returns:\n",
    "        - list of n recommended item indices\n",
    "        \"\"\"\n",
    "        # If the user has no interactions in training set, return random recommendations\n",
    "        if user_id not in self.user_items:\n",
    "            all_items = list(range(self.n_items))\n",
    "            recommendations = random.sample(all_items, min(n, len(all_items)))\n",
    "            return np.array(recommendations)\n",
    "        \n",
    "        # Predict scores for all items for this user\n",
    "        with torch.no_grad():\n",
    "            user_tensor = torch.LongTensor([user_id] * self.n_items).to(self.device)\n",
    "            item_tensor = torch.LongTensor(list(range(self.n_items))).to(self.device)\n",
    "            \n",
    "            scores = self.model(user_tensor, item_tensor).cpu().numpy()\n",
    "        \n",
    "        # If requested, exclude items the user has already interacted with\n",
    "        if exclude_seen:\n",
    "            for item_id in self.user_items[user_id]:\n",
    "                scores[item_id] = -np.inf\n",
    "        \n",
    "        # Get top n items by score\n",
    "        top_items = np.argsort(scores)[::-1][:n]\n",
    "        \n",
    "        return top_items\n",
    "\n",
    "#################################\n",
    "# RERANKER IMPLEMENTATION\n",
    "#################################\n",
    "\n",
    "class SimpleReranker:\n",
    "    \"\"\"\n",
    "    Simple reranker that balances original scores with diversity\n",
    "    \"\"\"\n",
    "    def __init__(self, model, alpha=0.7):\n",
    "        \"\"\"\n",
    "        Initialize reranker\n",
    "        \n",
    "        Parameters:\n",
    "        - model: trained recommender model\n",
    "        - alpha: weight for original scores (between 0 and 1)\n",
    "                 higher alpha means more focus on accuracy\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Calculate item popularity\n",
    "        self.item_popularity = np.zeros(model.n_items)\n",
    "        for user in range(model.n_users):\n",
    "            if user in model.user_items:\n",
    "                for item in model.user_items[user]:\n",
    "                    self.item_popularity[item] += 1\n",
    "        \n",
    "        # Normalize popularity\n",
    "        max_pop = np.max(self.item_popularity)\n",
    "        if max_pop > 0:\n",
    "            self.norm_popularity = self.item_popularity / max_pop\n",
    "        else:\n",
    "            self.norm_popularity = np.zeros_like(self.item_popularity)\n",
    "    \n",
    "    def rerank(self, user_id, n=10):\n",
    "        \"\"\"\n",
    "        Generate reranked recommendations\n",
    "        \"\"\"\n",
    "        # Get original recommendations as a larger candidate pool\n",
    "        candidates = self.model.recommend(user_id, n=n*3, exclude_seen=True)\n",
    "        \n",
    "        # Get scores for all items for this user\n",
    "        with torch.no_grad():\n",
    "            user_tensor = torch.LongTensor([user_id] * self.model.n_items).to(self.model.device)\n",
    "            item_tensor = torch.LongTensor(list(range(self.model.n_items))).to(self.model.device)\n",
    "            scores = self.model.model(user_tensor, item_tensor).cpu().numpy()\n",
    "        \n",
    "        # Initialize selected items\n",
    "        selected = []\n",
    "        \n",
    "        # Iteratively select items\n",
    "        while len(selected) < n and candidates.size > 0:\n",
    "            best_score = -np.inf\n",
    "            best_item = None\n",
    "            \n",
    "            for item in candidates:\n",
    "                if item in selected:\n",
    "                    continue\n",
    "                \n",
    "                # Original score component\n",
    "                score_orig = scores[item]\n",
    "                \n",
    "                # Diversity component\n",
    "                diversity_score = 0\n",
    "                if selected:\n",
    "                    # Use item factors to calculate similarity\n",
    "                    item_factors = self.model.item_factors[item]\n",
    "                    selected_factors = self.model.item_factors[selected]\n",
    "                    \n",
    "                    # Calculate average similarity\n",
    "                    similarities = []\n",
    "                    for sel_factors in selected_factors:\n",
    "                        # Cosine similarity\n",
    "                        dot_product = np.dot(item_factors, sel_factors)\n",
    "                        norm_product = np.linalg.norm(item_factors) * np.linalg.norm(sel_factors)\n",
    "                        if norm_product > 0:\n",
    "                            sim = dot_product / norm_product\n",
    "                        else:\n",
    "                            sim = 0\n",
    "                        similarities.append(sim)\n",
    "                    \n",
    "                    if similarities:\n",
    "                        avg_sim = np.mean(similarities)\n",
    "                        diversity_score = 1 - avg_sim\n",
    "                \n",
    "                # Novelty component (inverse popularity)\n",
    "                novelty_score = 1 - self.norm_popularity[item]\n",
    "                \n",
    "                # Calculate weighted score\n",
    "                combined_score = (\n",
    "                    self.alpha * score_orig + \n",
    "                    (1 - self.alpha) * 0.5 * diversity_score + \n",
    "                    (1 - self.alpha) * 0.5 * novelty_score\n",
    "                )\n",
    "                \n",
    "                if combined_score > best_score:\n",
    "                    best_score = combined_score\n",
    "                    best_item = item\n",
    "            \n",
    "            if best_item is None:\n",
    "                break\n",
    "                \n",
    "            selected.append(best_item)\n",
    "            candidates = candidates[candidates != best_item]\n",
    "            \n",
    "        return np.array(selected)\n",
    "\n",
    "class MMRReranker:\n",
    "    \"\"\"\n",
    "    Maximum Marginal Relevance (MMR) Reranker\n",
    "    \n",
    "    This reranker balances between relevance and diversity explicitly by\n",
    "    selecting items that maximize marginal relevance - items that are\n",
    "    both relevant to the user and different from already selected items.\n",
    "    \n",
    "    MMR formula: MMR = λ * rel(i) - (1-λ) * max(sim(i,j)) for j in selected items\n",
    "    \n",
    "    Where:\n",
    "    - rel(i) is the relevance of item i to the user\n",
    "    - sim(i,j) is the similarity between items i and j\n",
    "    - λ is a parameter that controls the trade-off between relevance and diversity\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, lambda_param=0.7):\n",
    "        \"\"\"\n",
    "        Initialize the MMR reranker\n",
    "        \n",
    "        Parameters:\n",
    "        - model: trained recommender model\n",
    "        - lambda_param: trade-off parameter between relevance and diversity (0-1)\n",
    "                        higher values favor relevance, lower values favor diversity\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.lambda_param = lambda_param\n",
    "        \n",
    "    def calculate_item_similarity(self, item1, item2):\n",
    "        \"\"\"\n",
    "        Calculate similarity between two items\n",
    "        \n",
    "        Parameters:\n",
    "        - item1: index of first item\n",
    "        - item2: index of second item\n",
    "        \n",
    "        Returns:\n",
    "        - similarity: similarity between items (0 to 1)\n",
    "        \"\"\"\n",
    "        # Calculate cosine similarity between item embeddings\n",
    "        item1_factors = self.model.item_factors[item1]\n",
    "        item2_factors = self.model.item_factors[item2]\n",
    "        \n",
    "        # Cosine similarity\n",
    "        dot_product = np.dot(item1_factors, item2_factors)\n",
    "        norm_product = np.linalg.norm(item1_factors) * np.linalg.norm(item2_factors)\n",
    "        \n",
    "        if norm_product == 0:\n",
    "            return 0\n",
    "        \n",
    "        return dot_product / norm_product\n",
    "    \n",
    "    def rerank(self, user_id, n=10, candidate_size=100):\n",
    "        \"\"\"\n",
    "        Generate reranked recommendations using Maximum Marginal Relevance\n",
    "        \n",
    "        Parameters:\n",
    "        - user_id: user index in the model\n",
    "        - n: number of recommendations to return\n",
    "        - candidate_size: number of initial candidates to consider\n",
    "        \n",
    "        Returns:\n",
    "        - reranked_items: list of reranked item indices\n",
    "        \"\"\"\n",
    "        # Get candidate items and their scores\n",
    "        candidates = self.model.recommend(user_id, n=candidate_size, exclude_seen=True)\n",
    "        \n",
    "        # Get scores for candidate items\n",
    "        with torch.no_grad():\n",
    "            user_tensor = torch.LongTensor([user_id] * self.model.n_items).to(self.model.device)\n",
    "            item_tensor = torch.LongTensor(list(range(self.model.n_items))).to(self.model.device)\n",
    "            relevance_scores = self.model.model(user_tensor, item_tensor).cpu().numpy()\n",
    "        \n",
    "        # Normalize relevance scores to [0,1] range for the candidates\n",
    "        candidate_scores = relevance_scores[candidates]\n",
    "        min_score = np.min(candidate_scores)\n",
    "        max_score = np.max(candidate_scores)\n",
    "        score_range = max_score - min_score\n",
    "        \n",
    "        if score_range > 0:\n",
    "            normalized_scores = (candidate_scores - min_score) / score_range\n",
    "        else:\n",
    "            normalized_scores = np.zeros_like(candidate_scores)\n",
    "        \n",
    "        # Initialize selected items\n",
    "        selected = []\n",
    "        \n",
    "        # Select first item (most relevant)\n",
    "        if candidates.size > 0:\n",
    "            selected.append(candidates[np.argmax(normalized_scores)])\n",
    "            remaining_candidates = set(candidates) - set(selected)\n",
    "        else:\n",
    "            remaining_candidates = set()\n",
    "        \n",
    "        # Iteratively select items using MMR\n",
    "        while len(selected) < n and remaining_candidates:\n",
    "            max_mmr = -np.inf\n",
    "            max_item = None\n",
    "            \n",
    "            for item in remaining_candidates:\n",
    "                # Get relevance component\n",
    "                item_idx = np.where(candidates == item)[0][0]\n",
    "                relevance = normalized_scores[item_idx]\n",
    "                \n",
    "                # Calculate diversity component (inverse of maximum similarity)\n",
    "                max_sim = 0\n",
    "                for selected_item in selected:\n",
    "                    sim = self.calculate_item_similarity(item, selected_item)\n",
    "                    max_sim = max(max_sim, sim)\n",
    "                \n",
    "                # Calculate MMR score\n",
    "                mmr_score = self.lambda_param * relevance - (1 - self.lambda_param) * max_sim\n",
    "                \n",
    "                if mmr_score > max_mmr:\n",
    "                    max_mmr = mmr_score\n",
    "                    max_item = item\n",
    "            \n",
    "            if max_item is not None:\n",
    "                selected.append(max_item)\n",
    "                remaining_candidates.remove(max_item)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        return np.array(selected)\n",
    "\n",
    "#################################\n",
    "# EVALUATION METRICS\n",
    "#################################\n",
    "\n",
    "def calculate_ndcg(recommended_items, relevant_items, relevant_scores, k=None):\n",
    "    \"\"\"\n",
    "    Calculate Normalized Discounted Cumulative Gain\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = len(recommended_items)\n",
    "    else:\n",
    "        k = min(k, len(recommended_items))\n",
    "    \n",
    "    # Create a dictionary mapping relevant items to their scores\n",
    "    relevance_map = {item_id: score for item_id, score in zip(relevant_items, relevant_scores)}\n",
    "    \n",
    "    # Calculate DCG\n",
    "    dcg = 0\n",
    "    for i, item_id in enumerate(recommended_items[:k]):\n",
    "        if item_id in relevance_map:\n",
    "            # Use rating as relevance score\n",
    "            rel = relevance_map[item_id]\n",
    "            # DCG formula: (2^rel - 1) / log2(i+2)\n",
    "            dcg += (2 ** rel - 1) / np.log2(i + 2)\n",
    "    \n",
    "    # Calculate ideal DCG (IDCG)\n",
    "    # Sort relevant items by their relevance scores in descending order\n",
    "    sorted_relevant = sorted(zip(relevant_items, relevant_scores), \n",
    "                           key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    idcg = 0\n",
    "    for i, (item_id, rel) in enumerate(sorted_relevant[:k]):\n",
    "        # IDCG formula: (2^rel - 1) / log2(i+2)\n",
    "        idcg += (2 ** rel - 1) / np.log2(i + 2)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate NDCG\n",
    "    ndcg = dcg / idcg\n",
    "    \n",
    "    return ndcg\n",
    "\n",
    "def calculate_precision(recommended_items, relevant_items):\n",
    "    \"\"\"\n",
    "    Calculate Precision@k\n",
    "    \"\"\"\n",
    "    # Count number of relevant items in recommended items\n",
    "    num_relevant_recommended = sum(1 for item in recommended_items if item in relevant_items)\n",
    "    \n",
    "    # Calculate precision\n",
    "    precision = num_relevant_recommended / len(recommended_items) if recommended_items else 0\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def calculate_recall(recommended_items, relevant_items):\n",
    "    \"\"\"\n",
    "    Calculate Recall@k\n",
    "    \"\"\"\n",
    "    # Count number of relevant items in recommended items\n",
    "    num_relevant_recommended = sum(1 for item in recommended_items if item in relevant_items)\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = num_relevant_recommended / len(relevant_items) if relevant_items else 0\n",
    "    \n",
    "    return recall\n",
    "\n",
    "def calculate_diversity_metrics(recommendations, item_popularity, total_items, tail_items=None):\n",
    "    \"\"\"\n",
    "    Calculate diversity metrics for a set of recommendations\n",
    "    \"\"\"\n",
    "    # Count occurrences of each item in recommendations\n",
    "    rec_counts = Counter(recommendations)\n",
    "    \n",
    "    # 1. Item Coverage\n",
    "    recommended_items = len(rec_counts)\n",
    "    item_coverage = recommended_items / total_items\n",
    "    \n",
    "    # 2. Gini Index\n",
    "    sorted_counts = sorted(rec_counts.values())\n",
    "    n = len(sorted_counts)\n",
    "    \n",
    "    if n == 0:\n",
    "        gini_index = 0\n",
    "    else:\n",
    "        cumulative_sum = 0\n",
    "        for i, count in enumerate(sorted_counts):\n",
    "            cumulative_sum += (i + 1) * count\n",
    "        \n",
    "        # Gini index formula\n",
    "        gini_index = (2 * cumulative_sum) / (n * sum(sorted_counts)) - (n + 1) / n\n",
    "    \n",
    "    # 3. Shannon Entropy\n",
    "    recommendations_count = sum(rec_counts.values())\n",
    "    probabilities = [count / recommendations_count for count in rec_counts.values()]\n",
    "    entropy = -sum(p * np.log2(p) for p in probabilities if p > 0)\n",
    "    \n",
    "    # Normalize entropy\n",
    "    max_entropy = np.log2(min(total_items, recommendations_count))\n",
    "    normalized_entropy = entropy / max_entropy if max_entropy > 0 else 0\n",
    "    \n",
    "    # 4. Tail Percentage\n",
    "    if tail_items is None:\n",
    "        # If tail_items not provided, use the bottom 20% by popularity\n",
    "        sorted_pop_indices = np.argsort(item_popularity)\n",
    "        num_tail_items = int(len(sorted_pop_indices) * 0.2)  # 20% least popular items\n",
    "        tail_items = set(sorted_pop_indices[:num_tail_items])\n",
    "    \n",
    "    tail_recommendations = sum(1 for item in recommendations if item in tail_items)\n",
    "    tail_percentage = tail_recommendations / len(recommendations) if recommendations else 0\n",
    "    \n",
    "    # Create results dictionary\n",
    "    metrics = {\n",
    "        'item_coverage': item_coverage,\n",
    "        'gini_index': gini_index,\n",
    "        'shannon_entropy': normalized_entropy,\n",
    "        'tail_percentage': tail_percentage\n",
    "    }\n",
    "    \n",
    "    return metrics, tail_items\n",
    "\n",
    "#################################\n",
    "# HELPER FUNCTIONS\n",
    "#################################\n",
    "\n",
    "def load_epinions(path=\"epinions/epinions.txt\"):\n",
    "    \"\"\"\n",
    "    Load the Epinions dataset\n",
    "    \n",
    "    Parameters:\n",
    "    - path: path to the epinions.txt file\n",
    "    \n",
    "    Returns:\n",
    "    - ratings_df: DataFrame with columns ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    - dummy_df: Empty DataFrame with item information structure (for compatibility)\n",
    "    \"\"\"\n",
    "    # Define column names for the raw data\n",
    "    columns = ['item_id', 'user_id', 'paid', 'timestamp', 'rating', 'review_text']\n",
    "    \n",
    "    # Try different encodings if one fails\n",
    "    encodings_to_try = ['utf-8', 'latin-1', 'ISO-8859-1', 'cp1252']\n",
    "    \n",
    "    # Generate sample data if we can't load the file\n",
    "    def generate_sample_data():\n",
    "        print(\"Generating sample Epinions data for demonstration purposes...\")\n",
    "        # Create synthetic data\n",
    "        np.random.seed(42)\n",
    "        n_users = 100\n",
    "        n_items = 50\n",
    "        n_ratings = 1000\n",
    "        \n",
    "        user_ids = [f\"user_{i}\" for i in range(n_users)]\n",
    "        item_ids = [f\"item_{i}\" for i in range(n_items)]\n",
    "        \n",
    "        # Generate random ratings\n",
    "        random_users = np.random.choice(user_ids, size=n_ratings)\n",
    "        random_items = np.random.choice(item_ids, size=n_ratings)\n",
    "        random_ratings = np.random.uniform(1, 5, size=n_ratings)\n",
    "        random_timestamps = np.random.randint(1000000000, 1600000000, size=n_ratings)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        sample_df = pd.DataFrame({\n",
    "            'user_id': random_users,\n",
    "            'item_id': random_items,\n",
    "            'rating': random_ratings,\n",
    "            'timestamp': random_timestamps\n",
    "        })\n",
    "        \n",
    "        # Create dummy movie DataFrame\n",
    "        dummy_df = pd.DataFrame(columns=['item_id', 'title', 'release_date', 'video_release_date',\n",
    "                                         'IMDb_URL'] + [f'genre_{i}' for i in range(19)])\n",
    "        \n",
    "        print(f\"Generated sample data with {len(sample_df)} ratings from {sample_df['user_id'].nunique()} users on {sample_df['item_id'].nunique()} items\")\n",
    "        \n",
    "        return sample_df, dummy_df\n",
    "    \n",
    "    # Try to load the actual data file\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            print(f\"Trying to load Epinions data with {encoding} encoding...\")\n",
    "            \n",
    "            # Read the file with whitespace as delimiter\n",
    "            # The review_text might contain spaces, so we'll need to handle that specially\n",
    "            data = []\n",
    "            with open(path, 'r', encoding=encoding) as file:\n",
    "                for line_num, line in enumerate(file, 1):\n",
    "                    try:\n",
    "                        # Split the line into components\n",
    "                        parts = line.strip().split(maxsplit=5)\n",
    "                        \n",
    "                        # If we don't have at least the first 5 columns, skip this line\n",
    "                        if len(parts) < 5:\n",
    "                            continue\n",
    "                        \n",
    "                        # Add review_text if it exists, otherwise set to empty string\n",
    "                        if len(parts) == 6:\n",
    "                            row = parts\n",
    "                        else:\n",
    "                            row = parts + ['']\n",
    "                        \n",
    "                        data.append(row)\n",
    "                    except Exception as line_error:\n",
    "                        print(f\"Warning: Error processing line {line_num}: {str(line_error)}\")\n",
    "                        continue\n",
    "            \n",
    "            # If we were able to read some data, proceed\n",
    "            if data:\n",
    "                # Create DataFrame\n",
    "                raw_df = pd.DataFrame(data, columns=columns)\n",
    "                \n",
    "                # Convert data types\n",
    "                raw_df['rating'] = pd.to_numeric(raw_df['rating'], errors='coerce')\n",
    "                raw_df['timestamp'] = pd.to_numeric(raw_df['timestamp'], errors='coerce')\n",
    "                raw_df['paid'] = pd.to_numeric(raw_df['paid'], errors='coerce')\n",
    "                \n",
    "                # Drop rows with invalid values\n",
    "                raw_df = raw_df.dropna(subset=['rating', 'timestamp', 'paid'])\n",
    "                \n",
    "                # Convert to proper types\n",
    "                raw_df['rating'] = raw_df['rating'].astype(float)\n",
    "                raw_df['timestamp'] = raw_df['timestamp'].astype(int)\n",
    "                \n",
    "                # Drop rows with missing values in essential columns\n",
    "                ratings_df = raw_df.dropna(subset=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "                \n",
    "                # Select only the columns we need\n",
    "                ratings_df = ratings_df[['user_id', 'item_id', 'rating', 'timestamp']]\n",
    "                \n",
    "                # Create an empty dummy_df with dummy structure\n",
    "                dummy_df = pd.DataFrame(columns=['item_id', 'title', 'release_date', 'video_release_date',\n",
    "                                               'IMDb_URL'] + [f'genre_{i}' for i in range(19)])\n",
    "                \n",
    "                # Return early if we have enough data\n",
    "                if len(ratings_df) > 0:\n",
    "                    print(f\"Successfully loaded Epinions dataset with {encoding} encoding\")\n",
    "                    print(f\"Loaded {len(ratings_df)} ratings from {ratings_df['user_id'].nunique()} users on {ratings_df['item_id'].nunique()} items\")\n",
    "                    return ratings_df, dummy_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Epinions dataset with {encoding} encoding: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # If we get here, all encoding attempts failed\n",
    "    print(\"All attempts to load the Epinions dataset failed. Generating sample data instead.\")\n",
    "    return generate_sample_data()\n",
    "\n",
    "def create_user_item_matrix(ratings_df):\n",
    "    \"\"\"\n",
    "    Create a sparse user-item interaction matrix from ratings\n",
    "    \"\"\"\n",
    "    # Create mappings from original IDs to matrix indices\n",
    "    user_ids = ratings_df['user_id'].unique()\n",
    "    item_ids = ratings_df['item_id'].unique()\n",
    "    \n",
    "    user_mapping = {user_id: i for i, user_id in enumerate(user_ids)}\n",
    "    item_mapping = {item_id: i for i, item_id in enumerate(item_ids)}\n",
    "    \n",
    "    # Map original IDs to matrix indices\n",
    "    rows = ratings_df['user_id'].map(user_mapping)\n",
    "    cols = ratings_df['item_id'].map(item_mapping)\n",
    "    \n",
    "    # Create binary matrix (1 if interaction exists, 0 otherwise)\n",
    "    data = np.ones(len(ratings_df))\n",
    "    user_item_matrix = csr_matrix((data, (rows, cols)), \n",
    "                                 shape=(len(user_mapping), len(item_mapping)))\n",
    "    \n",
    "    return user_item_matrix, user_mapping, item_mapping\n",
    "\n",
    "#################################\n",
    "# COMPREHENSIVE EVALUATION\n",
    "#################################\n",
    "\n",
    "def comprehensive_evaluation_multiple_rerankers(k=10, sample_size=None):\n",
    "    \"\"\"\n",
    "    Run a comprehensive evaluation measuring both accuracy and diversity for multiple rerankers\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"COMPREHENSIVE EVALUATION WITH MULTIPLE RERANKERS (k={k})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    print(\"\\nLoading Epinions dataset...\")\n",
    "    ratings_df, dummy_df = load_epinions()\n",
    "    \n",
    "    print(\"Splitting data for evaluation...\")\n",
    "    # Check if we can safely use stratification\n",
    "    value_counts = ratings_df['user_id'].value_counts()\n",
    "    if value_counts.min() >= 2:\n",
    "        # If all users have at least 2 ratings, we can stratify\n",
    "        print(\"Using stratified sampling...\")\n",
    "        train_df, test_df = train_test_split(\n",
    "            ratings_df, \n",
    "            test_size=0.2, \n",
    "            stratify=ratings_df['user_id'], \n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        # If some users have only 1 rating, we can't stratify\n",
    "        print(\"Using random sampling (some users have only 1 rating)...\")\n",
    "        train_df, test_df = train_test_split(\n",
    "            ratings_df, \n",
    "            test_size=0.2, \n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    print(\"Creating user-item matrix...\")\n",
    "    user_item_matrix, user_mapping, item_mapping = create_user_item_matrix(train_df)\n",
    "    \n",
    "    # Prepare for evaluation\n",
    "    reverse_user_mapping = {v: k for k, v in user_mapping.items()}\n",
    "    reverse_item_mapping = {v: k for k, v in item_mapping.items()}\n",
    "    \n",
    "    # Create test set ground truth\n",
    "    test_relevant_items = defaultdict(list)\n",
    "    test_relevant_scores = defaultdict(list)\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        item_id = row['item_id']\n",
    "        rating = row['rating']\n",
    "        \n",
    "        # Only include users and items that exist in our mappings\n",
    "        if user_id in user_mapping and item_id in item_mapping:\n",
    "            test_relevant_items[user_id].append(item_id)\n",
    "            test_relevant_scores[user_id].append(rating)\n",
    "    \n",
    "    # Train model - use fewer epochs for NeuMF since it's more computationally intensive\n",
    "    print(\"\\nTraining NeuMF model...\")\n",
    "    model = NeuMFRecommender(latent_dim=32, epochs=10, batch_size=256)\n",
    "    model.fit(user_item_matrix)\n",
    "    \n",
    "    # Initialize rerankers\n",
    "    print(\"\\nInitializing rerankers...\")\n",
    "    simple_reranker = SimpleReranker(model=model, alpha=0.7)\n",
    "    mmr_reranker = MMRReranker(model=model, lambda_param=0.7)\n",
    "    \n",
    "    # Setup dictionary for all rerankers' results\n",
    "    rerankers = {\n",
    "        \"Original NeuMF\": None,\n",
    "        \"Simple Reranker\": simple_reranker,\n",
    "        \"MMR Reranker\": mmr_reranker\n",
    "    }\n",
    "    \n",
    "    # Results dictionary\n",
    "    all_results = {}\n",
    "    \n",
    "    # Select users for evaluation\n",
    "    if sample_size is not None and sample_size < len(test_relevant_items):\n",
    "        eval_users = random.sample(list(test_relevant_items.keys()), sample_size)\n",
    "    else:\n",
    "        eval_users = list(test_relevant_items.keys())\n",
    "    \n",
    "    print(f\"\\nEvaluating {len(eval_users)} users...\")\n",
    "    \n",
    "    # Evaluate each reranker\n",
    "    for reranker_name, reranker in rerankers.items():\n",
    "        print(f\"\\nEvaluating {reranker_name}...\")\n",
    "        \n",
    "        # Initialize metrics collectors\n",
    "        ndcg_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        all_recs = []\n",
    "        \n",
    "        # Evaluate each user\n",
    "        for user_id in eval_users:\n",
    "            # Skip if user has no relevant items\n",
    "            if not test_relevant_items[user_id]:\n",
    "                continue\n",
    "            \n",
    "            user_idx = user_mapping[user_id]\n",
    "            \n",
    "            # Get recommendations\n",
    "            if reranker is None:  # Original NeuMF\n",
    "                rec_idx = model.recommend(user_idx, n=k)\n",
    "            else:  # Use reranker\n",
    "                rec_idx = reranker.rerank(user_idx, n=k)\n",
    "                \n",
    "            rec = [reverse_item_mapping[idx] for idx in rec_idx]\n",
    "            all_recs.extend(rec_idx)\n",
    "            \n",
    "            # Calculate accuracy metrics\n",
    "            ndcg_scores.append(calculate_ndcg(\n",
    "                rec, test_relevant_items[user_id], test_relevant_scores[user_id]\n",
    "            ))\n",
    "            precision_scores.append(calculate_precision(\n",
    "                rec, test_relevant_items[user_id]\n",
    "            ))\n",
    "            recall_scores.append(calculate_recall(\n",
    "                rec, test_relevant_items[user_id]\n",
    "            ))\n",
    "        \n",
    "        # Calculate average accuracy metrics\n",
    "        accuracy_metrics = {\n",
    "            f'ndcg@{k}': np.mean(ndcg_scores),\n",
    "            f'precision@{k}': np.mean(precision_scores),\n",
    "            f'recall@{k}': np.mean(recall_scores)\n",
    "        }\n",
    "        \n",
    "        # Calculate diversity metrics\n",
    "        # First calculate item popularity\n",
    "        item_popularity = np.zeros(model.n_items)\n",
    "        for user in range(model.n_users):\n",
    "            if user in model.user_items:\n",
    "                for item in model.user_items[user]:\n",
    "                    item_popularity[item] += 1\n",
    "        \n",
    "        # Then calculate diversity metrics\n",
    "        diversity_metrics, _ = calculate_diversity_metrics(\n",
    "            recommendations=all_recs,\n",
    "            item_popularity=item_popularity,\n",
    "            total_items=model.n_items\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        all_results[reranker_name] = {\n",
    "            'accuracy': accuracy_metrics,\n",
    "            'diversity': diversity_metrics\n",
    "        }\n",
    "    \n",
    "    # Print comparative results\n",
    "    print(\"\\n\" + \"=\"*30 + \" ACCURACY METRICS COMPARISON \" + \"=\"*30)\n",
    "    print(f\"{'Metric':<15}\", end='')\n",
    "    for reranker_name in rerankers.keys():\n",
    "        print(f\"{reranker_name:<20}\", end='')\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric in [f'ndcg@{k}', f'precision@{k}', f'recall@{k}']:\n",
    "        print(f\"{metric:<15}\", end='')\n",
    "        baseline = all_results[\"Original NeuMF\"]['accuracy'][metric]\n",
    "        for reranker_name in rerankers.keys():\n",
    "            value = all_results[reranker_name]['accuracy'][metric]\n",
    "            change = ((value - baseline) / baseline * 100) if baseline > 0 else float('inf')\n",
    "            \n",
    "            if reranker_name == \"Original NeuMF\":\n",
    "                print(f\"{value:.4f}{' '*15}\", end='')\n",
    "            else:\n",
    "                print(f\"{value:.4f} ({change:+.1f}%){' '*5}\", end='')\n",
    "        print()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30 + \" DIVERSITY METRICS COMPARISON \" + \"=\"*30)\n",
    "    print(f\"{'Metric':<15}\", end='')\n",
    "    for reranker_name in rerankers.keys():\n",
    "        print(f\"{reranker_name:<20}\", end='')\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric in ['item_coverage', 'gini_index', 'shannon_entropy', 'tail_percentage']:\n",
    "        print(f\"{metric:<15}\", end='')\n",
    "        baseline = all_results[\"Original NeuMF\"]['diversity'][metric]\n",
    "        for reranker_name in rerankers.keys():\n",
    "            value = all_results[reranker_name]['diversity'][metric]\n",
    "            change = ((value - baseline) / baseline * 100) if baseline > 0 else float('inf')\n",
    "            \n",
    "            if reranker_name == \"Original NeuMF\":\n",
    "                print(f\"{value:.4f}{' '*15}\", end='')\n",
    "            else:\n",
    "                print(f\"{value:.4f} ({change:+.1f}%){' '*5}\", end='')\n",
    "        print()\n",
    "    \n",
    "    # Print interpretations\n",
    "    print(\"\\n\" + \"=\"*30 + \" METRIC INTERPRETATIONS \" + \"=\"*30)\n",
    "    print(\"Accuracy Metrics:\")\n",
    "    print(\"- NDCG: Higher is better, measures ranking quality\")\n",
    "    print(\"- Precision: Higher is better, measures relevant item ratio in recommendations\")\n",
    "    print(\"- Recall: Higher is better, measures coverage of all relevant items\")\n",
    "    \n",
    "    print(\"\\nDiversity Metrics:\")\n",
    "    print(\"- Item Coverage: Higher means more catalog items are recommended\")\n",
    "    print(\"- Gini Index: Lower means more equality in item recommendations\")\n",
    "    print(\"- Shannon Entropy: Higher means more diverse recommendations\")\n",
    "    print(\"- Tail Percentage: Higher means more niche items are recommended\")\n",
    "    \n",
    "    # Return all results\n",
    "    return all_results\n",
    "\n",
    "def comprehensive_evaluation(alpha=0.7, k=10, sample_size=None):\n",
    "    \"\"\"\n",
    "    Run a comprehensive evaluation measuring both accuracy and diversity\n",
    "    \n",
    "    Parameters:\n",
    "    - alpha: weight for accuracy in reranking (0 to 1)\n",
    "    - k: number of recommendations to evaluate\n",
    "    - sample_size: number of users to sample (None for all users)\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"COMPREHENSIVE EVALUATION (alpha={alpha}, k={k})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    print(\"\\nLoading Epinions dataset...\")\n",
    "    ratings_df, dummy_df = load_epinions()\n",
    "    \n",
    "    print(\"Splitting data for evaluation...\")\n",
    "    # Check if we can safely use stratification\n",
    "    value_counts = ratings_df['user_id'].value_counts()\n",
    "    if value_counts.min() >= 2:\n",
    "        # If all users have at least 2 ratings, we can stratify\n",
    "        print(\"Using stratified sampling...\")\n",
    "        train_df, test_df = train_test_split(\n",
    "            ratings_df, \n",
    "            test_size=0.2, \n",
    "            stratify=ratings_df['user_id'], \n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        # If some users have only 1 rating, we can't stratify\n",
    "        print(\"Using random sampling (some users have only 1 rating)...\")\n",
    "        train_df, test_df = train_test_split(\n",
    "            ratings_df, \n",
    "            test_size=0.2, \n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    print(\"Creating user-item matrix...\")\n",
    "    user_item_matrix, user_mapping, item_mapping = create_user_item_matrix(train_df)\n",
    "    \n",
    "    # Prepare for evaluation\n",
    "    reverse_user_mapping = {v: k for k, v in user_mapping.items()}\n",
    "    reverse_item_mapping = {v: k for k, v in item_mapping.items()}\n",
    "    \n",
    "    # Create test set ground truth\n",
    "    test_relevant_items = defaultdict(list)\n",
    "    test_relevant_scores = defaultdict(list)\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        item_id = row['item_id']\n",
    "        rating = row['rating']\n",
    "        \n",
    "        # Only include users and items that exist in our mappings\n",
    "        if user_id in user_mapping and item_id in item_mapping:\n",
    "            test_relevant_items[user_id].append(item_id)\n",
    "            test_relevant_scores[user_id].append(rating)\n",
    "    \n",
    "    # Train model - use fewer epochs for NeuMF\n",
    "    print(\"\\nTraining NeuMF model...\")\n",
    "    model = NeuMFRecommender(latent_dim=32, epochs=10, batch_size=256)\n",
    "    model.fit(user_item_matrix)\n",
    "    \n",
    "    # Initialize reranker\n",
    "    print(\"\\nInitializing reranker with alpha =\", alpha)\n",
    "    reranker = SimpleReranker(model=model, alpha=alpha)\n",
    "    \n",
    "    # Select users for evaluation\n",
    "    if sample_size is not None and sample_size < len(test_relevant_items):\n",
    "        eval_users = random.sample(list(test_relevant_items.keys()), sample_size)\n",
    "    else:\n",
    "        eval_users = list(test_relevant_items.keys())\n",
    "    \n",
    "    print(f\"\\nEvaluating {len(eval_users)} users...\")\n",
    "    \n",
    "    # Initialize metrics collectors\n",
    "    original_ndcg = []\n",
    "    original_precision = []\n",
    "    original_recall = []\n",
    "    original_recs = []\n",
    "    \n",
    "    reranked_ndcg = []\n",
    "    reranked_precision = []\n",
    "    reranked_recall = []\n",
    "    reranked_recs = []\n",
    "    \n",
    "    # Evaluate each user\n",
    "    for user_id in eval_users:\n",
    "        # Skip if user has no relevant items\n",
    "        if not test_relevant_items[user_id]:\n",
    "            continue\n",
    "        \n",
    "        user_idx = user_mapping[user_id]\n",
    "        \n",
    "        # Get original recommendations\n",
    "        original_rec_idx = model.recommend(user_idx, n=k)\n",
    "        original_rec = [reverse_item_mapping[idx] for idx in original_rec_idx]\n",
    "        original_recs.extend(original_rec_idx)\n",
    "        \n",
    "        # Calculate accuracy metrics for original\n",
    "        original_ndcg.append(calculate_ndcg(\n",
    "            original_rec, test_relevant_items[user_id], test_relevant_scores[user_id]\n",
    "        ))\n",
    "        original_precision.append(calculate_precision(\n",
    "            original_rec, test_relevant_items[user_id]\n",
    "        ))\n",
    "        original_recall.append(calculate_recall(\n",
    "            original_rec, test_relevant_items[user_id]\n",
    "        ))\n",
    "        \n",
    "        # Get reranked recommendations\n",
    "        reranked_rec_idx = reranker.rerank(user_idx, n=k)\n",
    "        reranked_rec = [reverse_item_mapping[idx] for idx in reranked_rec_idx]\n",
    "        reranked_recs.extend(reranked_rec_idx)\n",
    "        \n",
    "        # Calculate accuracy metrics for reranked\n",
    "        reranked_ndcg.append(calculate_ndcg(\n",
    "            reranked_rec, test_relevant_items[user_id], test_relevant_scores[user_id]\n",
    "        ))\n",
    "        reranked_precision.append(calculate_precision(\n",
    "            reranked_rec, test_relevant_items[user_id]\n",
    "        ))\n",
    "        reranked_recall.append(calculate_recall(\n",
    "            reranked_rec, test_relevant_items[user_id]\n",
    "        ))\n",
    "    \n",
    "    # Calculate average accuracy metrics\n",
    "    orig_accuracy = {\n",
    "        f'ndcg@{k}': np.mean(original_ndcg),\n",
    "        f'precision@{k}': np.mean(original_precision),\n",
    "        f'recall@{k}': np.mean(original_recall)\n",
    "    }\n",
    "    \n",
    "    rerank_accuracy = {\n",
    "        f'ndcg@{k}': np.mean(reranked_ndcg),\n",
    "        f'precision@{k}': np.mean(reranked_precision),\n",
    "        f'recall@{k}': np.mean(reranked_recall)\n",
    "    }\n",
    "    \n",
    "    # Calculate diversity metrics\n",
    "    # First calculate item popularity\n",
    "    item_popularity = np.zeros(model.n_items)\n",
    "    for user in range(model.n_users):\n",
    "        if user in model.user_items:\n",
    "            for item in model.user_items[user]:\n",
    "                item_popularity[item] += 1\n",
    "    \n",
    "    # Then calculate diversity metrics\n",
    "    orig_diversity, tail_items = calculate_diversity_metrics(\n",
    "        recommendations=original_recs,\n",
    "        item_popularity=item_popularity,\n",
    "        total_items=model.n_items\n",
    "    )\n",
    "    \n",
    "    rerank_diversity, _ = calculate_diversity_metrics(\n",
    "        recommendations=reranked_recs,\n",
    "        item_popularity=item_popularity,\n",
    "        total_items=model.n_items,\n",
    "        tail_items=tail_items\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*30 + \" ACCURACY METRICS \" + \"=\"*30)\n",
    "    print(f\"{'Metric':<15} {'Original':<15} {'Reranked':<15} {'Change (%)':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for metric in [f'ndcg@{k}', f'precision@{k}', f'recall@{k}']:\n",
    "        orig = orig_accuracy[metric]\n",
    "        rerank = rerank_accuracy[metric]\n",
    "        change = ((rerank - orig) / orig) * 100 if orig > 0 else float('inf')\n",
    "        print(f\"{metric:<15} {orig:.4f}{' '*10} {rerank:.4f}{' '*10} {change:+.2f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30 + \" DIVERSITY METRICS \" + \"=\"*30)\n",
    "    print(f\"{'Metric':<20} {'Original':<15} {'Reranked':<15} {'Change (%)':<15}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for metric in ['item_coverage', 'gini_index', 'shannon_entropy', 'tail_percentage']:\n",
    "        orig = orig_diversity[metric]\n",
    "        rerank = rerank_diversity[metric]\n",
    "        change = ((rerank - orig) / orig) * 100 if orig > 0 else float('inf')\n",
    "        print(f\"{metric:<20} {orig:.4f}{' '*10} {rerank:.4f}{' '*10} {change:+.2f}%\")\n",
    "    \n",
    "    # Print interpretations\n",
    "    print(\"\\n\" + \"=\"*30 + \" METRIC INTERPRETATIONS \" + \"=\"*30)\n",
    "    print(\"Accuracy Metrics:\")\n",
    "    print(\"- NDCG: Higher is better, measures ranking quality\")\n",
    "    print(\"- Precision: Higher is better, measures relevant item ratio in recommendations\")\n",
    "    print(\"- Recall: Higher is better, measures coverage of all relevant items\")\n",
    "    \n",
    "    print(\"\\nDiversity Metrics:\")\n",
    "    print(\"- Item Coverage: Higher means more catalog items are recommended\")\n",
    "    print(\"- Gini Index: Lower means more equality in item recommendations\")\n",
    "    print(\"- Shannon Entropy: Higher means more diverse recommendations\")\n",
    "    print(\"- Tail Percentage: Higher means more niche items are recommended\")\n",
    "    \n",
    "    # Return all metrics\n",
    "    return {\n",
    "        'original': {\n",
    "            'accuracy': orig_accuracy,\n",
    "            'diversity': orig_diversity\n",
    "        },\n",
    "        'reranked': {\n",
    "            'accuracy': rerank_accuracy,\n",
    "            'diversity': rerank_diversity\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Execute with multiple rerankers when running the script directly\n",
    "if __name__ == \"__main__\":\n",
    "    comprehensive_evaluation_multiple_rerankers(k=10)\n",
    "    \n",
    "    # Uncomment to run single reranker evaluation with different alpha values\n",
    "    # comprehensive_evaluation(alpha=0.7, k=10)  # Default balance\n",
    "    # comprehensive_evaluation(alpha=0.5, k=10)  # Equal weight to accuracy and diversity\n",
    "    # comprehensive_evaluation(alpha=0.9, k=10)  # Strong focus on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a68fb-1b53-43b7-8a1d-12d5d786527a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
